{"cells":[{"cell_type":"markdown","metadata":{"id":"tSh_KMRsZ588"},"source":["# Instalações"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15629,"status":"ok","timestamp":1712860070991,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"oL_A237EZULC","outputId":"9ab6ff44-0c64-4427-b15f-9a96715f0bdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: cplex in /usr/local/python/3.10.13/lib/python3.10/site-packages (22.1.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: docplex in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.27.239)\n","Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from docplex) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: tensorflow in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n","Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.10/site-packages (3.8.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.21 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# @title Instalar\n","%pip install cplex\n","%pip install docplex\n","%pip install tensorflow\n","%pip install matplotlib"]},{"cell_type":"markdown","metadata":{"id":"4JEM7-7qV17W"},"source":["# Importações"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","id":"XXwpgpr8V-aL"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-17 16:26:26.393409: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-17 16:26:27.524739: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-17 16:26:30.567420: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-17 16:26:32.209412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# @title Importar\n","import os\n","import cplex\n","import numpy as np\n","import pandas as pd\n","from time import time\n","import tensorflow as tf\n","# from tensorflow import keras\n","from cplex import infinity\n","import docplex.mp.model as mp\n","from typing import List, Tuple, Any\n","from dataclasses import dataclass\n","from docplex.mp.constr import LinearConstraint\n","# import matplotlib.pyplot as plt\n","# from statistics import mean, stdev\n","# import matplotlib.patches as patches"]},{"cell_type":"markdown","metadata":{"id":"RVQu0m63WHX8"},"source":["# Drive"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2567,"status":"ok","timestamp":1712860073495,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"Pxh3fzUhVM23","outputId":"cc2268d0-19d9-4413-bd2c-06caa365dbf9"},"outputs":[],"source":["# @title Montar o Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# base_path = '/content/drive/My Drive/Colab Notebooks'\n","base_path = './'"]},{"cell_type":"code","execution_count":35,"metadata":{"cellView":"form","id":"wvR_LpCLVTXn"},"outputs":[],"source":["# @title Caminho para os arquivos no Google Drive\n","datasets_path = f'{base_path}/datasets'\n","# resultados_path = f'{base_path}/resultados'"]},{"cell_type":"markdown","metadata":{"id":"BHWYjoY5abiC"},"source":["# Milp"]},{"cell_type":"markdown","metadata":{"id":"JE9NjLNxalQU"},"source":["## Fischetti"]},{"cell_type":"code","execution_count":36,"metadata":{"cellView":"form","id":"SnTMbVoAaeTN"},"outputs":[],"source":["# @title Original\n","def codify_network_fischetti(\n","    mdl: mp.Model,\n","    layers,\n","    input_variables,\n","    auxiliary_variables,\n","    intermediate_variables,\n","    decision_variables,\n","    output_variables,\n","):\n","    output_bounds = []\n","    bounds = []\n","\n","    for i in range(len(layers)):\n","        A = layers[i].get_weights()[0].T\n","        b = layers[i].bias.numpy()\n","        x = input_variables if i == 0 else intermediate_variables[i - 1]\n","        if i != len(layers) - 1:\n","            s = auxiliary_variables[i]\n","            a = decision_variables[i]\n","            y = intermediate_variables[i]\n","        else:\n","            y = output_variables\n","\n","        for j in range(A.shape[0]):\n","            if i != len(layers) - 1:\n","                mdl.add_constraint(\n","                    A[j, :] @ x + b[j] == y[j] - s[j], ctname=f\"c_{i}_{j}\"\n","                )\n","                mdl.add_indicator(a[j], y[j] <= 0, 1)\n","                mdl.add_indicator(a[j], s[j] <= 0, 0)\n","\n","                mdl.maximize(y[j])\n","                mdl.solve()\n","                ub_y = mdl.solution.get_objective_value()\n","                mdl.remove_objective()\n","\n","                mdl.maximize(s[j])\n","                mdl.solve()\n","                ub_s = mdl.solution.get_objective_value()\n","                mdl.remove_objective()\n","\n","                y[j].set_ub(ub_y)\n","                s[j].set_ub(ub_s)\n","\n","                bounds.append([ub_s, ub_y])\n","\n","            else:\n","                mdl.add_constraint(A[j, :] @ x + b[j] == y[j], ctname=f\"c_{i}_{j}\")\n","                mdl.maximize(y[j])\n","                mdl.solve()\n","                ub = mdl.solution.get_objective_value()\n","                mdl.remove_objective()\n","\n","                mdl.minimize(y[j])\n","                mdl.solve()\n","                lb = mdl.solution.get_objective_value()\n","                mdl.remove_objective()\n","\n","                y[j].set_ub(ub)\n","                y[j].set_lb(lb)\n","\n","                output_bounds.append([lb, ub])\n","\n","                bounds.append([lb, ub])\n","\n","    return mdl, output_bounds, bounds"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"mu2cBOKXcejv"},"outputs":[],"source":["# @title Relaxado\n","def codify_network_fischetti_relaxed(\n","    mdl,\n","    layers,\n","    input_variables,\n","    auxiliary_variables,\n","    intermediate_variables,\n","    decision_variables,\n","    output_variables,\n","    output_bounds_binary_variables,\n","    bounds=[]\n","):\n","    output_bounds = []\n","\n","    for i in range(len(layers)):  # para cada camada\n","        A = layers[i].get_weights()[0].T\n","        b = layers[i].bias.numpy()\n","        x = input_variables if i == 0 else intermediate_variables[i - 1]\n","        if i != len(layers) - 1:\n","            s = auxiliary_variables[i]\n","            a = decision_variables[i]\n","            y = intermediate_variables[i]\n","        else:\n","            y = output_variables\n","\n","        for j in range(A.shape[0]):  # para cada neuronio da camada\n","            if i != len(layers) - 1:  # se não for a última camada(camada de saída)\n","                m_less, m_more = bounds[j]\n","                s[j].set_ub(m_less) # ub_s\n","                y[j].set_ub(m_more) # ub_y\n","                m_less = -m_less\n","                \n","                if m_more <= 0:\n","                    mdl.add_constraint(y[j] == 0)\n","                    continue\n","\n","                if m_less >= 0:\n","                    mdl.add_constraint(A[j, :] @ x + b[j] == y[j])\n","                    continue\n","\n","                if m_less < 0 and m_more > 0:\n","                    mdl.add_constraint(\n","                        A[j, :] @ x + b[j] == y[j] - s[j], ctname=f\"c_{i}_{j}\"\n","                    )\n","                    mdl.add_constraint(y[j] <= m_more * (1 - a[j]))\n","                    mdl.add_constraint(s[j] <= -m_less * a[j]) # TODO: verificar se o sinal está correto\n","                    continue\n","\n","            else:\n","                mdl.add_constraint(A[j, :] @ x + b[j] == y[j], ctname=f\"c_{i}_{j}\")\n","                lb, ub = output_bounds_binary_variables[j]\n","                y[j].set_lb(lb)\n","                y[j].set_ub(ub)\n","                output_bounds.append([lb, ub])\n","\n","    return mdl, output_bounds"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"VANGH8sPcmDu"},"outputs":[],"source":["# @title Tjeng\n","def codify_network_tjeng(\n","    mdl,\n","    layers,\n","    input_variables,\n","    intermediate_variables,\n","    decision_variables,\n","    output_variables,\n","):\n","    output_bounds = []\n","\n","    for i in range(len(layers)):\n","        A = layers[i].get_weights()[0].T\n","        b = layers[i].bias.numpy()\n","        x = input_variables if i == 0 else intermediate_variables[i - 1]\n","        if i != len(layers) - 1:\n","            a = decision_variables[i]\n","            y = intermediate_variables[i]\n","        else:\n","            y = output_variables\n","\n","        for j in range(A.shape[0]):\n","            mdl.maximize(A[j, :] @ x + b[j])\n","            mdl.solve()\n","            ub = mdl.solution.get_objective_value()\n","            mdl.remove_objective()\n","\n","            if ub <= 0 and i != len(layers) - 1:\n","                # print(\"ENTROU, o ub é negativo, logo y = 0\")\n","                mdl.add_constraint(y[j] == 0, ctname=f\"c_{i}_{j}\")\n","                continue\n","\n","            mdl.minimize(A[j, :] @ x + b[j])\n","            mdl.solve()\n","            lb = mdl.solution.get_objective_value()\n","            mdl.remove_objective()\n","\n","            if lb >= 0 and i != len(layers) - 1:\n","                # print(\"ENTROU, o lb >= 0, logo y = Wx + b\")\n","                mdl.add_constraint(A[j, :] @ x + b[j] ==\n","                                   y[j], ctname=f\"c_{i}_{j}\")\n","                continue\n","\n","            if i != len(layers) - 1:\n","                mdl.add_constraint(y[j] <= A[j, :] @ x +\n","                                   b[j] - lb * (1 - a[j]))\n","                mdl.add_constraint(y[j] >= A[j, :] @ x + b[j])\n","                mdl.add_constraint(y[j] <= ub * a[j])\n","\n","                # mdl.maximize(y[j])\n","                # mdl.solve()\n","                # ub_y = mdl.solution.get_objective_value()\n","                # mdl.remove_objective()\n","                # y[j].set_ub(ub_y)\n","\n","            else:\n","                mdl.add_constraint(A[j, :] @ x + b[j] == y[j])\n","                # y[j].set_ub(ub)\n","                # y[j].set_lb(lb)\n","                output_bounds.append([lb, ub])\n","\n","    return mdl, output_bounds"]},{"cell_type":"code","execution_count":39,"metadata":{"cellView":"form","id":"0Lltuu4Ncs0X"},"outputs":[],"source":["# @title Domain and Bounds\n","def get_domain_and_bounds_inputs(dataframe):\n","    domain = []\n","    bounds = []\n","    for column in dataframe.columns[:-1]:\n","        if len(dataframe[column].unique()) == 2:\n","            domain.append(\"B\")\n","            bound_inf = dataframe[column].min()\n","            bound_sup = dataframe[column].max()\n","            bounds.append([bound_inf, bound_sup])\n","        elif np.any(\n","            dataframe[column].unique().astype(np.int64)\n","            != dataframe[column].unique().astype(np.float64)\n","        ):\n","            domain.append(\"C\")\n","            bound_inf = dataframe[column].min()\n","            bound_sup = dataframe[column].max()\n","            bounds.append([bound_inf, bound_sup])\n","        else:\n","            domain.append(\"I\")\n","            bound_inf = dataframe[column].min()\n","            bound_sup = dataframe[column].max()\n","            bounds.append([bound_inf, bound_sup])\n","\n","    return domain, bounds"]},{"cell_type":"markdown","metadata":{"id":"3Y5TJWfoc7Mj"},"source":["## Codify Network"]},{"cell_type":"markdown","metadata":{"id":"qft3cA3-c9rr"},"source":["**X ---- E**\n","\n","x1 = 1 ∧ x2 = 3 ∧ F ∧ ¬E  \n","*INSATISFÁTIVEL*\n","\n","x1 ≥ 0 ∧ x1 ≤ 100 ∧ x2 = 3 ∧ F ∧ ¬E  \n","*INSATISFÁTIVEL* → x1 não é relevante,  \n","*SATISFATÍVEL* → x1 é relevante\n"]},{"cell_type":"code","execution_count":40,"metadata":{"cellView":"form","id":"cuRp1ZWGc65T"},"outputs":[],"source":["# @title Original\n","def codify_network(model, dataframe, method, relaxe_constraints):\n","    layers = model.layers\n","    num_features = layers[0].get_weights()[0].shape[0]\n","    mdl = mp.Model()\n","\n","    domain_input, bounds_input = get_domain_and_bounds_inputs(dataframe)\n","    bounds_input = np.array(bounds_input)\n","\n","    if relaxe_constraints:\n","        input_variables = mdl.continuous_var_list(\n","            num_features, lb=bounds_input[:,\n","                                          0], ub=bounds_input[:, 1], name=\"x\"\n","        )\n","    else:\n","        input_variables = []\n","        for i in range(len(domain_input)):\n","            lb, ub = bounds_input[i]\n","            if domain_input[i] == \"C\":\n","                input_variables.append(\n","                    mdl.continuous_var(lb=lb, ub=ub, name=f\"x_{i}\"))\n","            elif domain_input[i] == \"I\":\n","                input_variables.append(\n","                    mdl.integer_var(lb=lb, ub=ub, name=f\"x_{i}\"))\n","            elif domain_input[i] == \"B\":\n","                input_variables.append(mdl.binary_var(name=f\"x_{i}\"))\n","\n","    intermediate_variables = []\n","    auxiliary_variables = []\n","    decision_variables = []\n","\n","    for i in range(len(layers) - 1):\n","        weights = layers[i].get_weights()[0]\n","        intermediate_variables.append(\n","            mdl.continuous_var_list(\n","                weights.shape[1], lb=0, name=\"y\", key_format=f\"_{i}_%s\"\n","            )\n","        )\n","\n","        if method == \"fischetti\":\n","            auxiliary_variables.append(\n","                mdl.continuous_var_list(\n","                    weights.shape[1], lb=0, name=\"s\", key_format=f\"_{i}_%s\"\n","                )\n","            )\n","\n","        if relaxe_constraints and method == \"tjeng\":\n","            decision_variables.append(\n","                mdl.continuous_var_list(\n","                    weights.shape[1], name=\"a\", lb=0, ub=1, key_format=f\"_{i}_%s\"\n","                )\n","            )\n","        else:\n","            decision_variables.append(\n","                mdl.binary_var_list(\n","                    weights.shape[1], name=\"a\", lb=0, ub=1, key_format=f\"_{i}_%s\"\n","                )\n","            )\n","\n","    output_variables = mdl.continuous_var_list(\n","        layers[-1].get_weights()[0].shape[1], lb=-infinity, name=\"o\" #type: ignore\n","    )\n","\n","    if method == \"tjeng\":\n","        mdl, output_bounds = codify_network_tjeng(\n","            mdl,\n","            layers,\n","            input_variables,\n","            intermediate_variables,\n","            decision_variables,\n","            output_variables,\n","        )\n","    else:\n","        mdl, output_bounds, bounds = codify_network_fischetti(\n","            mdl,\n","            layers,\n","            input_variables,\n","            auxiliary_variables,\n","            intermediate_variables,\n","            decision_variables,\n","            output_variables,\n","        )\n","\n","    if relaxe_constraints:\n","        # Tighten domain of variables 'a'\n","        for i in decision_variables:\n","            for a in i:\n","                a.set_vartype(\"Integer\")\n","\n","        # Tighten domain of input variables\n","        for i, x in enumerate(input_variables):\n","            if domain_input[i] == \"I\":\n","                x.set_vartype(\"Integer\")\n","            elif domain_input[i] == \"B\":\n","                x.set_vartype(\"Binary\")\n","            elif domain_input[i] == \"C\":\n","                x.set_vartype(\"Continuous\")\n","\n","    return mdl, output_bounds, bounds\n"]},{"cell_type":"code","execution_count":41,"metadata":{"cellView":"form","id":"TIyR9M-WdGLy"},"outputs":[],"source":["# @title Relaxado\n","def codify_network_relaxed(\n","    model, dataframe, method, relaxe_constraints, output_bounds_binary_variables, bounds\n","):\n","    layers = model.layers\n","    num_features = layers[0].get_weights()[0].shape[0]\n","    mdl = mp.Model()\n","\n","    domain_input, bounds_input = get_domain_and_bounds_inputs(dataframe)\n","    bounds_input = np.array(bounds_input)\n","\n","    if relaxe_constraints:\n","        input_variables = mdl.continuous_var_list(\n","            num_features, lb=bounds_input[:,0], ub=bounds_input[:, 1], name=\"x\"\n","        )\n","    else:\n","        input_variables = []\n","        for i in range(len(domain_input)):\n","            lb, ub = bounds_input[i]\n","            input_variables.append(\n","                mdl.continuous_var(lb=lb, ub=ub, name=f\"x_{i}\"))\n","\n","    intermediate_variables = []\n","    auxiliary_variables = []\n","    decision_variables = []\n","\n","    for i in range(len(layers) - 1):\n","        weights = layers[i].get_weights()[0]\n","        intermediate_variables.append(\n","            mdl.continuous_var_list(\n","                weights.shape[1], lb=0, name=\"y\", key_format=f\"_{i}_%s\"\n","            )\n","        )\n","        auxiliary_variables.append(\n","            mdl.continuous_var_list(\n","                weights.shape[1], lb=0, name=\"s\", key_format=f\"_{i}_%s\"\n","            )\n","        )\n","        decision_variables.append(\n","            mdl.continuous_var_list(\n","                weights.shape[1], name=\"a\", lb=0, ub=1, key_format=f\"_{i}_%s\"\n","            )\n","        )\n","\n","    output_variables = mdl.continuous_var_list(\n","        layers[-1].get_weights()[0].shape[1], lb=-infinity, name=\"o\"\n","    )\n","\n","    mdl, output_bounds = codify_network_fischetti_relaxed(\n","        mdl,\n","        layers,\n","        input_variables,\n","        auxiliary_variables,\n","        intermediate_variables,\n","        decision_variables,\n","        output_variables,\n","        output_bounds_binary_variables,\n","        bounds=bounds\n","    )\n","\n","    # Tighten domain of variables 'a'\n","    for i in decision_variables:\n","        for a in i:\n","            a.set_vartype(\"Continuous\")\n","\n","    # Tighten domain of input variables\n","    for i, x in enumerate(input_variables):\n","        x.set_vartype(\"Continuous\")\n","\n","    return mdl, output_bounds\n"]},{"cell_type":"markdown","metadata":{"id":"dC7Rc_VpdNMg"},"source":["# Teste"]},{"cell_type":"code","execution_count":42,"metadata":{"cellView":"form","id":"KADB-MLEdK-j"},"outputs":[],"source":["# @title Insert Outputs\n","def insert_output_constraints_fischetti(\n","    mdl, output_variables, network_output, binary_variables\n","):\n","    # print(binary_variables)\n","    variable_output = output_variables[network_output]\n","    aux_var = 0\n","\n","    for i, output in enumerate(output_variables):\n","        if i != network_output:\n","            p = binary_variables[aux_var]\n","            aux_var += 1\n","            mdl.add_indicator(p, variable_output <= output, 1)\n","\n","    return mdl\n","\n","def insert_output_constraints_tjeng(\n","    mdl, output_variables, network_output, binary_variables, output_bounds\n","):\n","    variable_output = output_variables[network_output]\n","    upper_bounds_diffs = (\n","        output_bounds[network_output][1] - np.array(output_bounds)[:, 0]\n","    )  # Output i: oi - oj <= u1 = ui - lj\n","    aux_var = 0\n","\n","    for i, output in enumerate(output_variables):\n","        if i != network_output:\n","            ub = upper_bounds_diffs[i]\n","            z = binary_variables[aux_var]\n","            mdl.add_constraint(variable_output - output - ub * (1 - z) <= 0)\n","            aux_var += 1\n","\n","    return mdl\n"]},{"cell_type":"markdown","metadata":{"id":"_hvM4zE1dfZK"},"source":["## Explicações"]},{"cell_type":"markdown","metadata":{"id":"XmregFWBE9p0"},"source":["**X ---- E**\n","\n","x1 = 1 ∧ x2 = 3 ∧ F ∧ ¬E  \n","*INSATISFÁTIVEL*\n","\n","x1 ≥ 0 ∧ x1 ≤ 100 ∧ x2 = 3 ∧ F ∧ ¬E  \n","*INSATISFÁTIVEL* → x1 não é relevante,  \n","*SATISFATÍVEL* → x1 é relevante"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_min_max:str ='./datasets/digits/min_max/'\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"8e-_ffpNdgQq"},"outputs":[],"source":["# @title Original\n","def get_minimal_explanation(\n","    mdl,\n","    network_input,\n","    network_output,\n","    n_classes,\n","    method,\n","    output_bounds=None,\n","    initial_explanation=None,\n",") -> Tuple[List[LinearConstraint], mp.Model]:\n","    assert not (\n","        method == \"tjeng\" and output_bounds == None\n","    ), \"If the method tjeng is chosen, output_bounds must be passed.\"\n","\n","    output_variables = [mdl.get_var_by_name(f\"o_{i}\") for i in range(n_classes)]\n","\n","    if initial_explanation is None:\n","        input_constraints = mdl.add_constraints(\n","            [\n","                mdl.get_var_by_name(f\"x_{i}\") == feature.numpy()\n","                for i, feature in enumerate(network_input[0])\n","            ],\n","            names=\"input\",\n","        )\n","    else:\n","        input_constraints = mdl.add_constraints(\n","            [\n","                mdl.get_var_by_name(f\"x_{i}\") == network_input[0][i].numpy()\n","                for i in initial_explanation\n","            ],\n","            names=\"input\",\n","        )\n","\n","    binary_variables = mdl.binary_var_list(n_classes - 1, name=\"b\")\n","    mdl.add_constraint(mdl.sum(binary_variables) >= 1)\n","    # todo: salvar modelo durante a explicação\n","\n","    if method == \"tjeng\":\n","        mdl = insert_output_constraints_tjeng(\n","            mdl, output_variables, network_output, binary_variables, output_bounds\n","        )\n","    else:\n","        mdl = insert_output_constraints_fischetti(\n","            mdl, output_variables, network_output, binary_variables\n","        )\n","\n","\n","    # def verifica_lb_maior_que_ubs(lista):\n","    #   # Verifica cada tupla na lista\n","    #   for i, (lb, ub) in enumerate(lista):\n","    #       # Verifica se lb é maior que todos os ub's\n","    #       if all(lb > other_ub for j, (other_lb, other_ub) in enumerate(lista) if i != j):\n","    #           return True  # Encontrou um lb que é maior que todos os ub's\n","    #   return False  # Nenhum lb é maior que todos os ub's\n","\n","\n","    columns = [ (f'o_{i}_lb', f'o_{i}_ub') for i in range(len(output_variables))]\n","    elements_list = [element for tupla in columns for element in tupla]\n","    min_max_outputs_df = pd.DataFrame(columns = elements_list)\n","\n","    for constraint in input_constraints:\n","        mdl.remove_constraint(constraint)\n","        mdl.solve(log_output=False)\n","        relevante = False\n","        if mdl.solution is not None:\n","            relevante = True\n","            if relevante:\n","                antes = []\n","                depois = []\n","                for i in range(len(output_variables)):\n","                    o_i = output_variables[i]\n","                    lb = o_i.lb\n","                    ub = o_i.ub\n","                    antes.append((lb, ub))\n","\n","                    mdl.minimize(o_i)\n","                    sol = mdl.solve()\n","                    new_lb = sol.get_objective_value()\n","                    mdl.remove_objective()\n","                    sol = None\n","\n","                    mdl.maximize(o_i)\n","                    sol = mdl.solve()\n","                    new_ub = sol.get_objective_value()\n","                    mdl.remove_objective()\n","                    sol = None\n","                    # depois.append((new_lb, new_ub))\n","                    depois.append(new_lb)\n","                    depois.append(new_ub)\n","                min_max_outputs_df.loc[len(min_max_outputs_df)] = depois\n","            mdl.add_constraint(constraint)\n","    # min_max_outputs_df.to_csv(f'{path_results}/teste_min_max_original.csv')\n","    min_max_outputs_df.to_csv(f'{path_min_max}/original.csv') # TODO: adicionar o nome das instancias que estão sendo explicadas\n","    inputs = mdl.find_matching_linear_constraints(\"input\")\n","    return (inputs, mdl)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"AUK1dbs6dnkm"},"outputs":[],"source":["# @title Relaxado\n","def get_explanation_relaxed(\n","    mdl: mp.Model,\n","    network_input,\n","    network_output,\n","    n_classes,\n","    method,\n","    output_bounds=None,\n","    initial_explanation=None,\n","    delta=0.1,\n",") -> Tuple[List[LinearConstraint], mp.Model]:\n","    # todo: output_bounds só é relevante se o metodo for tjeng\n","    assert not (\n","        method == \"tjeng\" and output_bounds == None\n","    ), \"If the method tjeng is chosen, output_bounds must be passed.\"\n","\n","    output_variables = [mdl.get_var_by_name(f\"o_{i}\") for i in range(n_classes)]\n","\n","    if initial_explanation is None:\n","        input_constraints = mdl.add_constraints(\n","            [\n","                mdl.get_var_by_name(f\"x_{i}\") == feature.numpy()\n","                for i, feature in enumerate(network_input[0])\n","            ],\n","            names=\"input\",\n","        )\n","    else:\n","        input_constraints = mdl.add_constraints(\n","            [\n","                mdl.get_var_by_name(f\"x_{i}\") == network_input[0][i].numpy()\n","                for i in initial_explanation\n","            ],\n","            names=\"input\",\n","        )\n","        \n","    \n","    binary_variables = mdl.binary_var_list(n_classes - 1, name=\"b\")\n","    mdl.add_constraint(mdl.sum(binary_variables) >= 1) #type: ignore\n","    # todo: salvar modelo durante a explicação\n","\n","    if method == \"tjeng\":\n","        mdl = insert_output_constraints_tjeng(\n","            mdl, output_variables, network_output, binary_variables, output_bounds\n","        )\n","\n","    else:\n","        mdl = insert_output_constraints_fischetti(\n","            mdl, output_variables, network_output, binary_variables\n","        )\n","\n","    # def verifica_lb_maior_que_ubs(lista):\n","    #   # Verifica cada tupla na lista\n","    #   for i, (lb, ub) in enumerate(lista):\n","    #       # Verifica se lb é maior que todos os ub's\n","    #       if all(lb > other_ub for j, (other_lb, other_ub) in enumerate(lista) if i != j):\n","    #           return True  # Encontrou um lb que é maior que todos os ub's\n","    #   return False  # Nenhum lb é maior que todos os ub's\n","\n","    columns = [ (f'o_{i}_lb', f'o_{i}_ub') for i in range(len(output_variables))]\n","    elements_list = [element for tupla in columns for element in tupla]\n","    min_max_outputs_df = pd.DataFrame(columns = elements_list)\n","\n","    for constraint in input_constraints:\n","        mdl.remove_constraint(constraint)\n","\n","        x = constraint.get_left_expr()\n","        v = constraint.get_right_expr()\n","\n","        constraint_left = mdl.add_constraint(v - delta <= x)\n","        constraint_right = mdl.add_constraint(x <= v + delta)\n","\n","        relevante = False\n","        mdl.solve(log_output=False)\n","        if mdl.solution is not None:\n","            relevante = True\n","            if relevante:\n","                antes = []\n","                depois = []\n","                for i in range(len(output_variables)):\n","                    o_i = output_variables[i]\n","                    lb = o_i.lb\n","                    ub = o_i.ub\n","                    antes.append((lb, ub))\n","\n","                    mdl.minimize(o_i)\n","                    sol = mdl.solve()\n","                    new_lb = sol.get_objective_value()\n","                    mdl.remove_objective()\n","                    sol = None\n","\n","                    mdl.maximize(o_i)\n","                    sol = mdl.solve()\n","                    new_ub = sol.get_objective_value()\n","                    mdl.remove_objective()\n","                    sol = None\n","                    \n","                    depois.append(new_lb)\n","                    depois.append(new_ub)\n","                min_max_outputs_df.loc[len(min_max_outputs_df)] = depois\n","            mdl.add_constraint(constraint)\n","            mdl.remove_constraint(constraint_left)\n","            mdl.remove_constraint(constraint_right)\n","\n","\n","    min_max_outputs_df.to_csv(f'{path_min_max}/original.csv') # TODO: adicionar o nome das instancias que estão sendo explicadas\n","    inputs = mdl.find_matching_linear_constraints(\"input\")\n","    return (inputs, mdl)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.2.1)\n","Requirement already satisfied: absl-py in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (2.1.0)\n","Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from keras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keras) (0.3.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from optree->keras) (4.10.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install keras\n","import keras"]},{"cell_type":"markdown","metadata":{"id":"7rCXbEOqdr-n"},"source":["# Gerar Rede Neural"]},{"cell_type":"code","execution_count":45,"metadata":{"cellView":"form","id":"lL6CYKbtdqpC"},"outputs":[],"source":["# @title Gerar Rede Neural\n","def gerar_rede(dir_path: str, num_classes: int, n_neurons: int, n_hidden_layers: int):\n","    data_train = pd.read_csv(dir_path + \"/\" + \"train.csv\").to_numpy()\n","    data_test = pd.read_csv(dir_path + \"/\" + \"test.csv\").to_numpy()\n","\n","    x_train, y_train = data_train[:, :-1], data_train[:, -1]\n","    x_test, y_test = data_test[:, :-1], data_test[:, -1]\n","\n","    y_train_ohe = tf.keras.utils.to_categorical(\n","        y_train, num_classes=num_classes)\n","    y_test_ohe = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n","\n","    model = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.Input(shape=[x_train.shape[1]]),\n","        ]\n","    )\n","\n","    for _ in range(n_hidden_layers):\n","        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n","\n","    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","\n","    model_path = os.path.join(\n","        dir_path, \"models\", f\"model_{n_hidden_layers}layers_{n_neurons}neurons_teste.h5\"\n","    )\n","\n","    es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n","    ck = tf.keras.callbacks.ModelCheckpoint(\n","        model_path, monitor=\"val_accuracy\", save_best_only=True\n","    )\n","\n","    start = time()\n","    model.fit(\n","        x_train,\n","        y_train_ohe,\n","        batch_size=4,\n","        epochs=100,\n","        validation_data=(x_test, y_test_ohe),\n","        verbose=2,\n","        callbacks=[ck, es],\n","    )\n","    print(f\"Tempo de Treinamento: {time()-start}\")\n","\n","    # salvar modelo\n","    model = tf.keras.models.load_model(model_path)\n","\n","    # avaliar modelo com os dados de treinamento\n","    print(\"Resultado Treinamento\")\n","    model.evaluate(x_train, y_train_ohe, verbose=2)\n","\n","    # avaliar modelo com os dados de teste\n","    print(\"Resultado Teste\")\n","    model.evaluate(x_test, y_test_ohe, verbose=2)\n","    return model"]},{"cell_type":"code","execution_count":46,"metadata":{"cellView":"form","id":"grS-CB2-dwBb"},"outputs":[],"source":["# @title Gerar Rede Neural a partir de um dataset\n","def gerar_rede_com_dataset_iris(n_neurons=20, n_hidden_layers=1):\n","    dir_path = f\"{base_path}/datasets/iris\"\n","    num_classes = 3\n","    return gerar_rede(dir_path, num_classes, n_neurons, n_hidden_layers)\n","\n","\n","def gerar_rede_com_dataset_digits(n_neurons=20, n_hidden_layers=1):\n","    dir_path = f\"{base_path}/datasets/digits\"\n","    num_classes = 10\n","    return gerar_rede(dir_path, num_classes, n_neurons, n_hidden_layers)\n","\n","\n","def gerar_rede_com_dataset_wine(n_neurons=20, n_hidden_layers=1):\n","    dir_path = \"datasets\\\\wine\"\n","    num_classes = 10\n","    return gerar_rede(dir_path, num_classes, n_neurons, n_hidden_layers)"]},{"cell_type":"markdown","metadata":{"id":"n8ipyf9odx1P"},"source":["# Explicar Instância"]},{"cell_type":"code","execution_count":47,"metadata":{"cellView":"form","id":"XoVYHweWdyul"},"outputs":[],"source":["# @title explain_instance\n","def explain_instance(\n","    initial_network,\n","    configuration: dict,\n","    instance_index: int,\n","    data: pd.DataFrame,\n","    model_h5,\n","    n_classes\n",") -> Tuple[List[LinearConstraint], mp.Model]:\n","    method = configuration[\"method\"]\n","    (\n","        mdl_milp_with_binary_variable,\n","        output_bounds_binary_variables,\n","        bounds,\n","    ) = initial_network\n","    network_input = data.iloc[instance_index, :-1]\n","    # print(network_input)  # network_input = instance\n","    network_input = tf.reshape(tf.constant(network_input), (1, -1))\n","    network_output = model_h5.predict(tf.constant(network_input))[0]\n","    network_output = tf.argmax(network_output)\n","    mdl_aux = mdl_milp_with_binary_variable.clone()\n","    (explanation, model) = get_minimal_explanation(\n","        mdl_aux,\n","        network_input,\n","        network_output,\n","        n_classes=n_classes,\n","        method=method,\n","        output_bounds=output_bounds_binary_variables,\n","    )\n","\n","    return (explanation, model)"]},{"cell_type":"code","execution_count":48,"metadata":{"cellView":"form","id":"Kp2a4nqOd1Nl"},"outputs":[],"source":["# @title explain_instance_relaxed\n","def explain_instance_relaxed(\n","    initial_network,\n","    initial_network_relaxed,\n","    configuration: dict,\n","    instance_index: int,\n","    data: pd.DataFrame,\n","    model_h5,\n","    n_classes,\n","    delta=1.0,\n",") -> Tuple[List[LinearConstraint], mp.Model]:\n","    method = configuration[\"method\"]\n","    (\n","        mdl_milp_with_binary_variable,\n","        output_bounds_binary_variables,\n","        bounds,\n","    ) = initial_network\n","\n","    model_milp_relaxed, output_bounds_relaxed = initial_network_relaxed\n","    network_input = data.iloc[instance_index, :-1]\n","    # print(network_input)  # network_input = instance\n","    network_input = tf.reshape(tf.constant(network_input), (1, -1))\n","    network_output = model_h5.predict(tf.constant(network_input))[0]\n","    network_output = tf.argmax(network_output)\n","\n","    mdl_aux = model_milp_relaxed.clone()\n","\n","    (explanation, model) = get_explanation_relaxed(\n","        mdl_aux,\n","        network_input,\n","        network_output,\n","        n_classes=n_classes,\n","        method=method,\n","        output_bounds=output_bounds_binary_variables,\n","        delta=delta,\n","    )\n","\n","    return (explanation, model)"]},{"cell_type":"markdown","metadata":{"id":"GSeFHQg-eC0j"},"source":["# Benchmark"]},{"cell_type":"markdown","metadata":{"id":"JDG-q5d-diM-"},"source":["## Utils"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"ZNzdKtLKdhsp"},"outputs":[],"source":["def export_milp_as_lp(mdl: mp.Model, file: str):\n","  mdl.export_as_lp(f\"{file}\")"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"BuWxa9mFdr5n"},"outputs":[],"source":["def read_cplex_model(file: str):\n","  return cplex.Cplex(file)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"nd3k7ymod6Q-"},"outputs":[],"source":["def convert_string_to_pixel(pixel_str: str, matrix_size: tuple[int, int]) -> tuple[int, int]:\n","    # Remover o prefixo \"x_\"\n","    pixel_number = int(pixel_str.split(\"_\")[1])\n","    # Obter as dimensões da matriz\n","    rows, cols = matrix_size\n","    # Calcular as coordenadas do pixel\n","    row_index = pixel_number // cols\n","    col_index = pixel_number % cols\n","    return row_index, col_index"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"yf9l82hWd7qr"},"outputs":[],"source":["def get_coordinates_from_explanation(\n","  explanation: list[LinearConstraint],\n","  matrix_size: tuple[int, int],\n",") -> list[tuple[int, int]]:\n","    coordinates = []\n","    for constraint in explanation:\n","        # Extrair coordenadas da variável associada à restrição linear\n","        variable_name = constraint.left_expr.name\n","        x, y = convert_string_to_pixel(variable_name, matrix_size)\n","        coordinates.append((x, y))\n","    return coordinates"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":85,"metadata":{"id":"k8Z9bMoTeO42"},"outputs":[],"source":["def benchmark_instance( \n","    initial_network: Any,\n","    initial_network_relaxed: Any,\n","    configurations: list,\n","    model_h5: Any,\n","    n_classes: int,\n","    data: pd.DataFrame,\n","    results: pd.DataFrame,\n","    path_results: str,\n","    instance_index: int,\n","    file_results: str,\n","    resultados: pd.DataFrame,\n","    delta = 0.1,\n","    use_milp_original=False,\n","    matrix_size = (8, 8)):\n","    (\n","        tempo_original,\n","        len_original,\n","        explanation_original\n","    ) = [None] * 3\n","\n","    if use_milp_original:\n","        # explain_instance original\n","        start_time = time()\n","        (explanation_original, model_milp_original) = explain_instance(\n","            initial_network = initial_network,\n","            configuration = configurations[0],\n","            instance_index = instance_index,\n","            data = data,\n","            model_h5 = model_h5,\n","            n_classes = n_classes\n","        )\n","        end_time = time()\n","        tempo_original = end_time - start_time\n","        len_original = len(explanation_original)\n","\n","    # explain_instance_relaxed local\n","    start_time = time()\n","    (explanation_relaxed, model_milp_relaxed) = explain_instance_relaxed(\n","        initial_network = initial_network,\n","        initial_network_relaxed = initial_network_relaxed,\n","        configuration = configurations[0],\n","        instance_index = instance_index,\n","        data = data,\n","        model_h5 = model_h5,\n","        n_classes = n_classes,\n","        delta=delta,\n","    )\n","\n","    end_time = time()\n","    tempo_relaxado = end_time - start_time\n","    len_relaxado = len(explanation_relaxed)\n","\n","    # explain_instance_relaxed global\n","    start_time = time()\n","    (explanation_relaxed_global, model_milp_relaxed_global) = explain_instance_relaxed(\n","        initial_network = initial_network,\n","        initial_network_relaxed = initial_network_relaxed,\n","        configuration = configurations[0], #todo: modificar para passar o metodo diretamente\n","        instance_index = instance_index,\n","        data = data,\n","        model_h5 = model_h5,\n","        n_classes = n_classes,\n","        delta=1,  # global\n","    )\n","\n","    end_time = time()\n","    tempo_relaxado_global = end_time - start_time\n","    len_relaxado_global = len(explanation_relaxed_global)\n","\n","    len_resultados = len(resultados)\n","    resultados.loc[len_resultados] = [\n","        instance_index,\n","        tempo_original,\n","        tempo_relaxado,\n","        tempo_relaxado_global,\n","        len_original,\n","        len_relaxado,\n","        len_relaxado_global,\n","        delta,\n","        get_coordinates_from_explanation(explanation_original, matrix_size) if explanation_original is not None else None,\n","        get_coordinates_from_explanation(explanation_relaxed, matrix_size),\n","        get_coordinates_from_explanation(explanation_relaxed_global, matrix_size),\n","    ]\n","\n","    # exportar modelos\n","    if explanation_original is not None:\n","        export_milp_as_lp(model_milp_original, f\"{path_results}/original_after\")\n","    export_milp_as_lp(model_milp_relaxed, f\"{path_results}/relaxed_after\")\n","\n","    # salvar\n","    resultados.to_csv(file_results, index=False)\n","    return [explanation_original, explanation_relaxed, explanation_relaxed_global]"]},{"cell_type":"markdown","metadata":{"id":"9bf7TRqLd4WD"},"source":["## Datasets"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"g_EN0g04d12g"},"outputs":[],"source":["@dataclass\n","class Dataset:\n","    dir_path: str\n","    model: str\n","    n_classes: int\n","\n","datasets: List[Dataset] = [\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_0layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_1layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_2layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_3layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_4layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/digits\",\n","        model=\"models/model_5layers_20neurons.h5\",\n","        n_classes=10,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/iris\",\n","        model=\"models/model_1layers_20neurons.h5\",\n","        n_classes=3,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/iris\",\n","        model=\"models/model_1layers_20neurons.h5\",\n","        n_classes=3,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/iris\",\n","        model=\"models/model_5layers_20neurons.h5\",\n","        n_classes=3,\n","    ),\n","    Dataset(\n","        dir_path=f\"{datasets_path}/iris\",\n","        model=\"models/model_6layers_20neurons.h5\",\n","        n_classes=3,\n","    ),\n","]\n","\n","configurations = [{\"method\": \"fischetti\", \"relaxe_constraints\": True}]"]},{"cell_type":"markdown","metadata":{"id":"rWdeXNs5eHik"},"source":["## Configurações"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"9-lAhtyYd39D"},"outputs":[],"source":["def read_dataset(dir_path, model_h5_file):\n","  data_test = pd.read_csv(f\"{dir_path}/test.csv\")\n","  data_train = pd.read_csv(f\"{dir_path}/train.csv\")\n","  data = data_train._append(data_test)\n","  model_h5 = tf.keras.models.load_model(f\"{dir_path}/{model_h5_file}\")\n","  return (data, model_h5)"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1712860073506,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"vzIy5yihsOwt","outputId":"c071e4e7-6010-4fdf-e157-7fda719e0663"},"outputs":[{"data":{"text/plain":["Dataset(dir_path='.//datasets/digits', model='models/model_0layers_20neurons.h5', n_classes=10)"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["dataset_index = 0\n","datasets[dataset_index]"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"t5vnPV7qeKLM"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}],"source":["dir_path, n_classes, model_h5_file = (\n","    datasets[dataset_index].dir_path,\n","    datasets[dataset_index].n_classes,\n","    datasets[dataset_index].model,\n",")\n","\n","configuration_index = 0\n","(data, model_h5) = read_dataset(dir_path, model_h5_file)\n","\n","method = configurations[configuration_index][\"method\"]\n","relaxe_constraints = configurations[configuration_index][\"relaxe_constraints\"]"]},{"cell_type":"markdown","metadata":{"id":"Zsvjj3zIeM7M"},"source":["## Diretório dos resultados\n"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"_hFJScISIBkx"},"outputs":[],"source":["def create_results_directory(dir_path:str, model_h5_file:str)->str:\n","  file_name_model = (f\"{dir_path}/{model_h5_file}\")\n","  file_name_model_result = (f\"{dir_path}/results/{model_h5_file}\")\n","  if not os.path.exists(file_name_model_result):\n","      os.makedirs(file_name_model_result)\n","  return file_name_model_result"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"6yCnDUezeOmN"},"outputs":[],"source":["file_result = create_results_directory(dir_path, model_h5_file)"]},{"cell_type":"markdown","metadata":{"id":"mJn7HQi6eQAs"},"source":["## Modelos MILP"]},{"cell_type":"markdown","metadata":{"id":"1R7afKlEeSOy"},"source":["### Modelo MILP Original"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"-lY8TfBXeQ6t"},"outputs":[],"source":["# todo: pegar output_bounds_binary_variables e bounds a partir do modelo já pronto, ao inves de salvar durante a modelagem\n","# todo: modificar para verificar se o modelo já está codificado antes de codificar(ou seja, ler o arquivo .lp)\n","initial_network = codify_network(model_h5, data, method, relaxe_constraints)\n","(\n","    mdl_milp_with_binary_variable,\n","    output_bounds_binary_variables,\n","    bounds,\n",") = initial_network"]},{"cell_type":"markdown","metadata":{"id":"WdrfSzyteWI6"},"source":["### Modelo MILP Relaxado"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1712860089983,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"h2YpdAL7eW4p","outputId":"8bbb0d80-cdb8-4c7c-aef7-f2519a2fff7d"},"outputs":[],"source":["initial_network_relaxed = codify_network_relaxed(\n","    model_h5,\n","    data,\n","    method,\n","    relaxe_constraints,\n","    output_bounds_binary_variables,\n","    bounds=bounds,\n",")"]},{"cell_type":"markdown","metadata":{"id":"oc3vCVLOeaXc"},"source":["### Salvar Modelos MILPs\n"]},{"cell_type":"markdown","metadata":{"id":"o644_PHOed4L"},"source":["#### Salvar modelo MILP original\n"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"fUSW7RsmegVK"},"outputs":[],"source":["export_milp_as_lp(mdl_milp_with_binary_variable, f'{file_result}/outputs_original')"]},{"cell_type":"markdown","metadata":{"id":"XchvYAd-eh28"},"source":["#### Salvar modelo MILP relaxado"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"0pt6wnf2ejZX"},"outputs":[],"source":["(mdl_relaxed, output_bounds_relaxed) = initial_network_relaxed\n","export_milp_as_lp(mdl_relaxed, f'{file_result}/relaxed')"]},{"cell_type":"markdown","metadata":{"id":"IxO0qrEHepnn"},"source":["### Abrir Modelos MILPs"]},{"cell_type":"markdown","metadata":{"id":"GOCRKvlter8h"},"source":["#### Abrir Modelo MILP Original"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"8390TqCsevQQ"},"outputs":[],"source":["file_path_lp = f\"{file_result}/outputs_original.lp\"\n","# model_read = cplex.Cplex(caminho_do_arquivo_lp)\n","model_read = read_cplex_model(file_path_lp)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96,"status":"ok","timestamp":1712860089985,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"esGECd7Wew9M","outputId":"8879b9c2-7418-49db-b456-c4e9fffe4e1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'y_0_0', 's_0_0', 'y_0_1', 's_0_1', 'y_0_2', 's_0_2', 'y_0_3', 's_0_3', 'y_0_4', 's_0_4', 'y_0_5', 's_0_5', 'y_0_6', 's_0_6', 'y_0_7', 's_0_7', 'y_0_8', 's_0_8', 'y_0_9', 's_0_9', 'y_0_10', 's_0_10', 'y_0_11', 's_0_11', 'y_0_12', 's_0_12', 'y_0_13', 's_0_13', 'y_0_14', 's_0_14', 'y_0_15', 's_0_15', 'y_0_16', 's_0_16', 'y_0_17', 's_0_17', 'y_0_18', 's_0_18', 'y_0_19', 's_0_19', 'y_1_0', 's_1_0', 'y_1_1', 's_1_1', 'y_1_2', 's_1_2', 'y_1_3', 's_1_3', 'y_1_4', 's_1_4', 'y_1_5', 's_1_5', 'y_1_6', 's_1_6', 'y_1_7', 's_1_7', 'y_1_8', 's_1_8', 'y_1_9', 's_1_9', 'y_1_10', 's_1_10', 'y_1_11', 's_1_11', 'y_1_12', 's_1_12', 'y_1_13', 's_1_13', 'y_1_14', 's_1_14', 'y_1_15', 's_1_15', 'y_1_16', 's_1_16', 'y_1_17', 's_1_17', 'y_1_18', 's_1_18', 'y_1_19', 's_1_19', 'o_0', 'o_1', 'o_2', 'o_3', 'o_4', 'o_5', 'o_6', 'o_7', 'o_8', 'o_9', 'a_0_0', 'a_0_1', 'a_0_2', 'a_0_3', 'a_0_4', 'a_0_5', 'a_0_6', 'a_0_7', 'a_0_8', 'a_0_9', 'a_0_10', 'a_0_11', 'a_0_12', 'a_0_13', 'a_0_14', 'a_0_15', 'a_0_16', 'a_0_17', 'a_0_18', 'a_0_19', 'a_1_0', 'a_1_1', 'a_1_2', 'a_1_3', 'a_1_4', 'a_1_5', 'a_1_6', 'a_1_7', 'a_1_8', 'a_1_9', 'a_1_10', 'a_1_11', 'a_1_12', 'a_1_13', 'a_1_14', 'a_1_15', 'a_1_16', 'a_1_17', 'a_1_18', 'a_1_19']\n"]}],"source":["var_names = model_read.variables.get_names()\n","var_names_filtered = [nome for nome in var_names if nome.startswith('')]\n","print(var_names_filtered.__str__())\n"]},{"cell_type":"markdown","metadata":{"id":"Fr_c4GWMezSE"},"source":["#### Abrir Modelo MILP Relaxado"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"46QUKXzte0uy"},"outputs":[],"source":["path_file_lp_relaxed = f\"{file_result}/relaxed.lp\"\n","model_relaxed_read = read_cplex_model(path_file_lp_relaxed)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88,"status":"ok","timestamp":1712860089986,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"LMTubTbXe2P5","outputId":"3b86ca42-3338-4f70-af4f-8c61ee056846"},"outputs":[{"name":"stdout","output_type":"stream","text":["['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'y_0_0', 's_0_0', 'a_0_0', 'y_0_1', 's_0_1', 'a_0_1', 'y_0_2', 's_0_2', 'a_0_2', 'y_0_3', 's_0_3', 'a_0_3', 'y_0_4', 's_0_4', 'a_0_4', 'y_0_5', 's_0_5', 'a_0_5', 'y_0_6', 's_0_6', 'a_0_6', 'y_0_7', 's_0_7', 'a_0_7', 'y_0_8', 's_0_8', 'a_0_8', 'y_0_9', 's_0_9', 'a_0_9', 'y_0_10', 's_0_10', 'a_0_10', 'y_0_11', 's_0_11', 'a_0_11', 'y_0_12', 's_0_12', 'a_0_12', 'y_0_13', 's_0_13', 'a_0_13', 'y_0_14', 's_0_14', 'a_0_14', 'y_0_15', 's_0_15', 'a_0_15', 'y_0_16', 's_0_16', 'a_0_16', 'y_0_17', 's_0_17', 'a_0_17', 'y_0_18', 's_0_18', 'a_0_18', 'y_0_19', 's_0_19', 'a_0_19', 'y_1_0', 's_1_0', 'a_1_0', 'y_1_1', 's_1_1', 'a_1_1', 'y_1_2', 's_1_2', 'a_1_2', 'y_1_3', 's_1_3', 'a_1_3', 'y_1_4', 's_1_4', 'a_1_4', 'y_1_5', 's_1_5', 'a_1_5', 'y_1_6', 's_1_6', 'a_1_6', 'y_1_7', 's_1_7', 'a_1_7', 'y_1_8', 's_1_8', 'a_1_8', 'y_1_9', 's_1_9', 'a_1_9', 'y_1_10', 's_1_10', 'a_1_10', 'y_1_11', 's_1_11', 'a_1_11', 'y_1_12', 's_1_12', 'a_1_12', 'y_1_13', 's_1_13', 'a_1_13', 'y_1_14', 's_1_14', 'a_1_14', 'y_1_15', 's_1_15', 'a_1_15', 'y_1_16', 's_1_16', 'a_1_16', 'y_1_17', 's_1_17', 'a_1_17', 'y_1_18', 's_1_18', 'a_1_18', 'y_1_19', 's_1_19', 'a_1_19', 'o_0', 'o_1', 'o_2', 'o_3', 'o_4', 'o_5', 'o_6', 'o_7', 'o_8', 'o_9']\n"]}],"source":["var_names_relaxed = model_relaxed_read.variables.get_names()\n","var_names_relaxed_filtered = [nome for nome in var_names_relaxed if nome.startswith('')]\n","print(var_names_relaxed_filtered)"]},{"cell_type":"markdown","metadata":{"id":"5_wF83Kxe4DQ"},"source":["## Executar Benchmark"]},{"cell_type":"code","execution_count":70,"metadata":{"cellView":"form","id":"yKa8lDWLn76w"},"outputs":[],"source":["# @title criar dataframe dos resultados\n","\n","path_results = f\"{file_result}\"\n","if not os.path.exists(path_results):\n","    os.makedirs(path_results)\n","file_results = f\"{path_results}/df.csv\"\n","if os.path.exists(file_results):\n","    resultados = pd.read_csv(file_results)\n","else:\n","    resultados = pd.DataFrame(\n","        columns=[\n","            \"instance_index\",\n","            \"tempo_original\",\n","            \"tempo_relaxado\",\n","            \"tempo_relaxado_global\",\n","            \"len_original\",\n","            \"len_relaxado\",\n","            \"len_relaxado_global\",\n","            \"delta\",\n","            \"explanation\",\n","            \"explanation_relaxed\",\n","            \"explanation_relaxed_global\",\n","        ]\n","    )"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"kjCXFzOuKHiU"},"outputs":[],"source":["minimo = 94\n","quantidade = 1\n","maximo = minimo + quantidade"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":580807,"status":"ok","timestamp":1712861024469,"user":{"displayName":"Mac Myller da Silva Carlos","userId":"16066511552472195111"},"user_tz":180},"id":"eyN9Ia_tfByq","outputId":"2decde8d-5483-4283-c836-03e42b78bf73"},"outputs":[{"name":"stdout","output_type":"stream","text":["index: 94\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"]}],"source":["delta = 1 - 0.7\n","for index in range(minimo, maximo):\n","  print(f\"index: {index}\")\n","  r = benchmark_instance(\n","    data = data,\n","    results = resultados,\n","    path_results = path_results,\n","    instance_index = index,\n","    delta = delta,\n","    use_milp_original=True,\n","    matrix_size = (8, 8),\n","    configurations=configurations,\n","    model_h5=model_h5,\n","    n_classes=n_classes,\n","    initial_network=initial_network,\n","    initial_network_relaxed=initial_network_relaxed,\n","    file_results=file_results,\n","    resultados=resultados,\n","  )\n","\n","# alterar o minimo para que não execute a celula novamente se o minimo não for modificado anteriormente\n","minimo = maximo"]}],"metadata":{"colab":{"collapsed_sections":["4JEM7-7qV17W","RVQu0m63WHX8","n8ipyf9odx1P","JDG-q5d-diM-","9bf7TRqLd4WD","rWdeXNs5eHik","Zsvjj3zIeM7M","1R7afKlEeSOy","WdrfSzyteWI6","o644_PHOed4L","XchvYAd-eh28","IxO0qrEHepnn","GOCRKvlter8h","Fr_c4GWMezSE"],"provenance":[{"file_id":"1khztwiJAfVgM1brdfv9zQMTDnY-OsXU4","timestamp":1712621694112}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
