{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cplex\n",
    "import pandas as pd \n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import docplex.mp.model as mp\n",
    "from docplex.mp import model_reader\n",
    "from typing import List, Tuple, Any\n",
    "from docplex.mp.constr import LinearConstraint \n",
    "from utils.explanations import get_minimal_explanation, get_explanation_relaxed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title explain_instance\n",
    "def explain_instance(\n",
    "    initial_network,\n",
    "    configuration: dict,\n",
    "    instance_index: int,\n",
    "    data: pd.DataFrame,\n",
    "    model_h5,\n",
    "    n_classes\n",
    ") -> Tuple[List[LinearConstraint], mp.Model, int]:\n",
    "    method = configuration[\"method\"]\n",
    "    (\n",
    "        mdl_milp_with_binary_variable,\n",
    "        output_bounds_binary_variables,\n",
    "        bounds,\n",
    "    ) = initial_network\n",
    "    network_input = data.iloc[instance_index, :-1]\n",
    "    # print(network_input)  # network_input = instance\n",
    "    network_input = tf.reshape(tf.constant(network_input), (1, -1))\n",
    "    network_output = model_h5.predict(tf.constant(network_input))[0]\n",
    "    network_output = tf.argmax(network_output)\n",
    "    mdl_aux = mdl_milp_with_binary_variable.clone()\n",
    "    (explanation, model) = get_minimal_explanation(\n",
    "        mdl_aux,\n",
    "        network_input,\n",
    "        network_output,\n",
    "        n_classes=n_classes,\n",
    "        method=method,\n",
    "        output_bounds=output_bounds_binary_variables\n",
    "    )\n",
    "\n",
    "    return (explanation, model, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title explain_instance_relaxed\n",
    "def explain_instance_relaxed(\n",
    "    initial_network,\n",
    "    initial_network_relaxed,\n",
    "    configuration: dict,\n",
    "    instance_index: int,\n",
    "    data: pd.DataFrame,\n",
    "    model_h5,\n",
    "    n_classes,\n",
    "    delta=1.0\n",
    ") -> Tuple[List[LinearConstraint], mp.Model]:\n",
    "    method = configuration[\"method\"]\n",
    "    (\n",
    "        mdl_milp_with_binary_variable,\n",
    "        output_bounds_binary_variables,\n",
    "        bounds,\n",
    "    ) = initial_network\n",
    "\n",
    "    model_milp_relaxed, output_bounds_relaxed = initial_network_relaxed\n",
    "    network_input = data.iloc[instance_index, :-1]\n",
    "    # print(network_input)  # network_input = instance\n",
    "    network_input = tf.reshape(tf.constant(network_input), (1, -1))\n",
    "    network_output = model_h5.predict(tf.constant(network_input))[0]\n",
    "    network_output = tf.argmax(network_output)\n",
    "\n",
    "    mdl_aux = model_milp_relaxed.clone()\n",
    "\n",
    "    (explanation, model) = get_explanation_relaxed(\n",
    "        mdl_aux,\n",
    "        network_input,\n",
    "        network_output,\n",
    "        n_classes=n_classes,\n",
    "        # method=method,\n",
    "        # output_bounds=output_bounds_binary_variables,\n",
    "        delta=delta,\n",
    "        # min_max_results_path_relaxed_global = min_max_results_path_relaxed_\n",
    "    )\n",
    "\n",
    "    return (explanation, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_milp_as_lp(mdl: mp.Model, file: str):\n",
    "  mdl.export_as_lp(f\"{file}\")\n",
    "\n",
    "def read_cplex_model(file: str):\n",
    "  return cplex.Cplex(file)\n",
    "\n",
    "def convert_string_to_pixel(pixel_str: str, matrix_size: tuple[int, int]) -> tuple[int, int]:\n",
    "    # Remover o prefixo \"x_\"\n",
    "    pixel_number = int(pixel_str.split(\"_\")[1])\n",
    "    # Obter as dimensões da matriz\n",
    "    rows, cols = matrix_size\n",
    "    # Calcular as coordenadas do pixel\n",
    "    row_index = pixel_number // cols\n",
    "    col_index = pixel_number % cols\n",
    "    return row_index, col_index\n",
    "  \n",
    "def get_coordinates_from_explanation(\n",
    "  explanation: list[LinearConstraint],\n",
    "  matrix_size: tuple[int, int],\n",
    ") -> list[tuple[int, int]]:\n",
    "    coordinates = []\n",
    "    for constraint in explanation:\n",
    "        # Extrair coordenadas da variável associada à restrição linear\n",
    "        variable_name = constraint.left_expr.name\n",
    "        x, y = convert_string_to_pixel(variable_name, matrix_size)\n",
    "        coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "def create_directory(path_to_create:str):\n",
    "  array_splited = path_to_create.split('/')\n",
    "  min_max_path_full = './'\n",
    "  for path in array_splited:\n",
    "    if path == '':\n",
    "      continue\n",
    "    min_max_path_full = f'{min_max_path_full}/{path}'\n",
    "    if not os.path.exists(min_max_path_full):\n",
    "      os.makedirs(min_max_path_full)\n",
    "  return array_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_instance( \n",
    "    initial_network: Any,\n",
    "    initial_network_relaxed: Any,\n",
    "    model_h5: Any,\n",
    "    n_classes: int,\n",
    "    data: pd.DataFrame,\n",
    "    instance_index: int,\n",
    "    resultados: pd.DataFrame,\n",
    "    file_result:str,\n",
    "    delta = 0.1):\n",
    " \n",
    "    (\n",
    "        mdl_milp_with_binary_variable,\n",
    "        output_bounds_binary_variables,\n",
    "        bounds,\n",
    "    ) = initial_network\n",
    "    \n",
    "    network_input = data.iloc[instance_index, :-1]\n",
    "    network_input = tf.reshape(tf.constant(network_input), (1, -1))\n",
    "    network_output = model_h5.predict(tf.constant(network_input))[0]\n",
    "    network_output = tf.argmax(network_output)\n",
    "    \n",
    "    # Relaxed\n",
    "    model_milp_relaxed, output_bounds_relaxed = initial_network_relaxed\n",
    "    mdl_aux_2 = model_milp_relaxed.clone()\n",
    "    start_time = time()\n",
    "    (explanation_relaxed_global, model_relaxed_global) = get_explanation_relaxed(\n",
    "        mdl_aux_2,\n",
    "        network_input,\n",
    "        network_output,\n",
    "        n_classes=n_classes,\n",
    "        # method=method,\n",
    "        # output_bounds=output_bounds_binary_variables,\n",
    "        delta=1,\n",
    "        # min_max_results_path_relaxed_global = 'min_max_results_path_relaxed_'\n",
    "    )\n",
    "    end_time = time()\n",
    "    time_relaxed_global = end_time - start_time\n",
    "    len_relaxed_global = len(explanation_relaxed_global)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Original\n",
    "    #mdl_aux = mdl_milp_with_binary_variable.clone()\n",
    "    #start_time = time()\n",
    "    #(explanation, model) = get_minimal_explanation(\n",
    "    #    mdl_aux,\n",
    "    #    network_input,\n",
    "    #    network_output,\n",
    "    #    n_classes=n_classes,\n",
    "    #    method=method,\n",
    "    #    output_bounds=output_bounds_binary_variables,\n",
    "    #    min_max_results_path_original = 'min_max_results_path_original'\n",
    "    #)\n",
    "    #end_time = time()\n",
    "    #tempo_original = end_time - start_time\n",
    "    #len_original = len(explanation)\n",
    "    #\n",
    "    \n",
    "    \n",
    "    len_resultados = len(resultados)\n",
    "    resultados.loc[len_resultados] = [\n",
    "        instance_index,\n",
    "        \n",
    "        None, #tempo_original,\n",
    "        None,\n",
    "        time_relaxed_global,\n",
    "        \n",
    "        None, #len_original, \n",
    "        None,\n",
    "        len_relaxed_global,\n",
    "        \n",
    "        delta,\n",
    "        \n",
    "        None, #get_coordinates_from_explanation(explanation, matrix_size) if explanation is not None else None,\n",
    "        None,\n",
    "        explanation_relaxed_global, # get_coordinates_from_explanation(explanation_relaxed_global, matrix_size),\n",
    "        # explanation_relaxed_global, \n",
    "    ]\n",
    "    resultados.to_csv(f'{file_result}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"name\": \"digits\",\n",
    "  \"n_classes\": 10,\n",
    "}\n",
    "dataset_name, n_classes = config[\"name\"], config[\"n_classes\"]\n",
    "\n",
    "data_train = pd.read_csv(f\"datasets/{config['name']}/train.csv\")\n",
    "data_test = pd.read_csv(f\"datasets/{config['name']}/test.csv\")\n",
    "data = pd.concat([data_train, data_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_network = None\n",
    "initial_network_relaxed = None\n",
    "configurations = None\n",
    "model_h5 = None \n",
    "instance_index = 1\n",
    "resultados = pd\n",
    "file_result = f'{file_result}/df.csv'\n",
    "delta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_instance( \n",
    "initial_network = initial_network,\n",
    "initial_network_relaxed = initial_network_relaxed,\n",
    "model_h5 = model_h5,\n",
    "n_classes = n_classes,\n",
    "data = data,\n",
    "instance_index = instance_index,\n",
    "resultados = resultados,\n",
    "file_result = file_result,\n",
    "delta = None\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parâmetros dados\n",
    "dvc = 50\n",
    "delta = 0.05\n",
    "log_delta_inv = np.log(1 / delta)\n",
    "\n",
    "# Função de crescimento do conjunto de hipóteses (aproximação)\n",
    "def mH(N, dvc):\n",
    "    return N**dvc\n",
    "\n",
    "# Valores de N (ajustado para começar de 2)\n",
    "N_values = np.arange(2, 10001)\n",
    "\n",
    "# Cálculo dos limites (com tratamento de erros)\n",
    "def safe_log(x):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.where(x <= 0, 0, np.log(x))\n",
    "\n",
    "vc_bound = np.sqrt((8 / N_values) * safe_log(4 * mH(2 * N_values, dvc) / delta))\n",
    "rademacher_bound = np.sqrt((2 * safe_log(2 * N_values * mH(N_values, dvc)) / N_values)) + np.sqrt((2 * log_delta_inv) / N_values) + 1 / N_values\n",
    "parrondo_bound = np.sqrt((1 / N_values) * (2 * vc_bound + safe_log(6 * mH(2 * N_values, dvc) / delta)))\n",
    "devroye_bound = np.sqrt((1 / (2 * N_values)) * (4 * vc_bound * (1 + vc_bound) + safe_log(4 * mH(N_values**2, dvc) / delta)))\n",
    "\n",
    "# Plotando os limites\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(N_values, vc_bound, label='Original VC Bound')\n",
    "plt.plot(N_values, rademacher_bound, label='Rademacher Penalty Bound')\n",
    "plt.plot(N_values, parrondo_bound, label='Parrondo and Van den Broek')\n",
    "plt.plot(N_values, devroye_bound, label='Devroye')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Bound')\n",
    "plt.title('Bounds on Generalization Error as a Function of N')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Verificando os valores para N = 10.000\n",
    "N_large = 10000\n",
    "vc_large = np.sqrt((8 / N_large) * safe_log(4 * mH(2 * N_large, dvc) / delta))\n",
    "rademacher_large = np.sqrt((2 * safe_log(2 * N_large * mH(N_large, dvc)) / N_large)) + np.sqrt((2 * log_delta_inv) / N_large) + 1 / N_large\n",
    "parrondo_large = np.sqrt((1 / N_large) * (2 * vc_large + safe_log(6 * mH(2 * N_large, dvc) / delta)))\n",
    "devroye_large = np.sqrt((1 / (2 * N_large)) * (4 * vc_large * (1 + vc_large) + safe_log(4 * mH(N_large**2, dvc) / delta)))\n",
    "\n",
    "(vc_large, rademacher_large, parrondo_large, devroye_large)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
